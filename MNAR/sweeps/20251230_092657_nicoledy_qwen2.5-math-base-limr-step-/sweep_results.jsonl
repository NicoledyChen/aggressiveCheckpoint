{"step": 1, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-1", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-1", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:26:58Z", "finished_at": "2025-12-30T09:26:59Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 2, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-2", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-2", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:26:58Z", "finished_at": "2025-12-30T09:26:59Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 3, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-3", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-3", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:26:59Z", "finished_at": "2025-12-30T09:27:00Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 4, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-4", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-4", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:26:59Z", "finished_at": "2025-12-30T09:27:00Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 6, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-6", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-6", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:00Z", "finished_at": "2025-12-30T09:27:01Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 5, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-5", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-5", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:00Z", "finished_at": "2025-12-30T09:27:01Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 7, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-7", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-7", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:01Z", "finished_at": "2025-12-30T09:27:02Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 8, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-8", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-8", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:01Z", "finished_at": "2025-12-30T09:27:02Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 9, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-9", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-9", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:02Z", "finished_at": "2025-12-30T09:27:02Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 10, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-10", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-10", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:02Z", "finished_at": "2025-12-30T09:27:03Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 12, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-12", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-12", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:03Z", "finished_at": "2025-12-30T09:27:03Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 11, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-11", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-11", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:02Z", "finished_at": "2025-12-30T09:27:04Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 13, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-13", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-13", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:03Z", "finished_at": "2025-12-30T09:27:04Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 14, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-14", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-14", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:04Z", "finished_at": "2025-12-30T09:27:05Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 15, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-15", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-15", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:04Z", "finished_at": "2025-12-30T09:27:05Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 16, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-16", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-16", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:05Z", "finished_at": "2025-12-30T09:27:05Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 17, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-17", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-17", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:05Z", "finished_at": "2025-12-30T09:27:06Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 18, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-18", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-18", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:05Z", "finished_at": "2025-12-30T09:27:06Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 19, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-19", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-19", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:06Z", "finished_at": "2025-12-30T09:27:07Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 20, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-20", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-20", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:06Z", "finished_at": "2025-12-30T09:27:07Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 22, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-22", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-22", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:07Z", "finished_at": "2025-12-30T09:27:08Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 21, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-21", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-21", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:07Z", "finished_at": "2025-12-30T09:27:09Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 23, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-23", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-23", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:08Z", "finished_at": "2025-12-30T09:27:09Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 24, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-24", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-24", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:09Z", "finished_at": "2025-12-30T09:27:09Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 25, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-25", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-25", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:09Z", "finished_at": "2025-12-30T09:27:10Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 26, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-26", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-26", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:09Z", "finished_at": "2025-12-30T09:27:10Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 27, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-27", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-27", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:10Z", "finished_at": "2025-12-30T09:27:11Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 28, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-28", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-28", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:10Z", "finished_at": "2025-12-30T09:27:11Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 30, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-30", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-30", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:11Z", "finished_at": "2025-12-30T09:27:12Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 29, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-29", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-29", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:11Z", "finished_at": "2025-12-30T09:27:12Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 31, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-31", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-31", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:12Z", "finished_at": "2025-12-30T09:27:13Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 32, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-32", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-32", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:12Z", "finished_at": "2025-12-30T09:27:13Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 34, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-34", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-34", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:13Z", "finished_at": "2025-12-30T09:27:13Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 33, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-33", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-33", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:13Z", "finished_at": "2025-12-30T09:27:13Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 35, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-35", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-35", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:13Z", "finished_at": "2025-12-30T09:27:14Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 36, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-36", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-36", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:13Z", "finished_at": "2025-12-30T09:27:14Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 38, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-38", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-38", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:14Z", "finished_at": "2025-12-30T09:27:15Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 37, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-37", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-37", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:14Z", "finished_at": "2025-12-30T09:27:15Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 39, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-39", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-39", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:15Z", "finished_at": "2025-12-30T09:27:16Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 40, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-40", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-40", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:15Z", "finished_at": "2025-12-30T09:27:16Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
{"step": 41, "hf_repo": "nicoledy/qwen2.5-math-base-limr-step-41", "deploy_name": "NicoledyChen/qwen2.5-math-base-limr-step-41", "deploy_id": null, "gpu": "1xA100-80GB", "num_gpus": 1, "max_batch_size": 32, "min_instances": 1, "max_instances": 1, "started_at": "2025-12-30T09:27:16Z", "finished_at": "2025-12-30T09:27:17Z", "deploy_status": null, "deletion_error": null, "error": {"type": "DeepInfraDeployError", "message": "POST /deploy/llm failed status=422 body={'detail': [{'type': 'enum', 'loc': ['body', 'gpu'], 'msg': \"Input should be 'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\", 'input': '1xA100-80GB', 'ctx': {'expected': \"'L4-24GB', 'L40S-48GB', 'A100-80GB', 'H100-80GB', 'H200-141GB', 'B200-180GB' or 'other'\"}}]}"}}
